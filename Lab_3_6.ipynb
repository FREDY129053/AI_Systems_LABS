{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmO8YDxH1H5JbuakUy11zg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FREDY129053/AI_Systems_LABS/blob/main/Lab_3_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Лаба 3.6: Нейронные сети"
      ],
      "metadata": {
        "id": "cZ1dy-bgJfRC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "cij7LyXHIYol",
        "outputId": "4784a444-b2ec-4ecb-c6c7-2f079d80b5cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размерность датасета: (19997, 19)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
              "0  221900.0         3          1         1180      5650     1.0           0   \n",
              "1  538000.0         3          2         2570      7242     2.0           0   \n",
              "2  180000.0         2          1          770     10000     1.0           0   \n",
              "3  604000.0         4          3         1960      5000     1.0           0   \n",
              "4  510000.0         3          2         1680      8080     1.0           0   \n",
              "\n",
              "   condition  grade      lat     long  was_renovated_post90  has_basement  \\\n",
              "0          3      7  47.5112 -122.257                     0             0   \n",
              "1          3      7  47.7210 -122.319                     1             1   \n",
              "2          3      6  47.7379 -122.233                     0             0   \n",
              "3          5      7  47.5208 -122.393                     0             1   \n",
              "4          3      8  47.6168 -122.045                     0             0   \n",
              "\n",
              "   viewed  sale_month  yr_built_1950_to_1975  yr_built_1975_to_1997  \\\n",
              "0       0          10                    1.0                    0.0   \n",
              "1       0          12                    1.0                    0.0   \n",
              "2       0           2                    0.0                    0.0   \n",
              "3       0          12                    1.0                    0.0   \n",
              "4       0           2                    0.0                    1.0   \n",
              "\n",
              "   yr_built_1997_to_2015  yr_built_pre1950  \n",
              "0                    0.0               0.0  \n",
              "1                    0.0               0.0  \n",
              "2                    0.0               1.0  \n",
              "3                    0.0               0.0  \n",
              "4                    0.0               0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ceaa58ee-1196-4e56-a98b-2abc4586dd06\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>was_renovated_post90</th>\n",
              "      <th>has_basement</th>\n",
              "      <th>viewed</th>\n",
              "      <th>sale_month</th>\n",
              "      <th>yr_built_1950_to_1975</th>\n",
              "      <th>yr_built_1975_to_1997</th>\n",
              "      <th>yr_built_1997_to_2015</th>\n",
              "      <th>yr_built_pre1950</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1180</td>\n",
              "      <td>5650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>538000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2570</td>\n",
              "      <td>7242</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>47.7210</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>180000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>770</td>\n",
              "      <td>10000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>-122.233</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>604000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1960</td>\n",
              "      <td>5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>-122.393</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>510000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1680</td>\n",
              "      <td>8080</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>47.6168</td>\n",
              "      <td>-122.045</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ceaa58ee-1196-4e56-a98b-2abc4586dd06')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ceaa58ee-1196-4e56-a98b-2abc4586dd06 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ceaa58ee-1196-4e56-a98b-2abc4586dd06');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-770d381f-ab83-4bad-b112-34427d31e346\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-770d381f-ab83-4bad-b112-34427d31e346')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-770d381f-ab83-4bad-b112-34427d31e346 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_copy",
              "summary": "{\n  \"name\": \"df_copy\",\n  \"rows\": 19997,\n  \"fields\": [\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 261955.84895003773,\n        \"min\": 75000.0,\n        \"max\": 1955000.0,\n        \"num_unique_values\": 3688,\n        \"samples\": [\n          928990.0,\n          436472.0,\n          642450.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bedrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bathrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          0,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sqft_living\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 752,\n        \"min\": 370,\n        \"max\": 4690,\n        \"num_unique_values\": 820,\n        \"samples\": [\n          1397,\n          3540,\n          2350\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sqft_lot\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10164,\n        \"min\": 520,\n        \"max\": 130680,\n        \"num_unique_values\": 8835,\n        \"samples\": [\n          1829,\n          9958,\n          4132\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"floors\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.540609789370065,\n        \"min\": 1.0,\n        \"max\": 3.5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1.0,\n          2.0,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"waterfront\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"condition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"grade\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 12,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          3,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13902763528316064,\n        \"min\": 47.1764,\n        \"max\": 47.7776,\n        \"num_unique_values\": 4923,\n        \"samples\": [\n          47.7734,\n          47.2815\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"long\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12714884730435008,\n        \"min\": -122.512,\n        \"max\": -121.804,\n        \"num_unique_values\": 605,\n        \"samples\": [\n          -121.879,\n          -122.024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"was_renovated_post90\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_basement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"viewed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sale_month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          8,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"yr_built_1950_to_1975\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4469484321736796,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"yr_built_1975_to_1997\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.42708528442458293,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"yr_built_1997_to_2015\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.42378119506149886,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"yr_built_pre1950\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.43275612836212857,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/lab_2_ready_df.csv')\n",
        "df_copy = df.copy()\n",
        "\n",
        "print(f\"Размерность датасета: {df_copy.shape}\")\n",
        "df_copy.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Разбиение данных"
      ],
      "metadata": {
        "id": "Lyw_pi0LJ0HS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_copy.drop('price', axis=1)\n",
        "y = df_copy['price']"
      ],
      "metadata": {
        "id": "N5zNl29fKURN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
        "print(f\"Validation set shape: X_val={X_val.shape}, y_val={y_val.shape}\")\n",
        "print(f\"Test set shape: X_test={X_test.shape}, y_test={y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwDTpoI5J12I",
        "outputId": "da16d026-46ff-48ce-f0f9-f69ef4a27bda"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: X_train=(13997, 18), y_train=(13997,)\n",
            "Validation set shape: X_val=(3000, 18), y_val=(3000,)\n",
            "Test set shape: X_test=(3000, 18), y_test=(3000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Модели"
      ],
      "metadata": {
        "id": "Afml4sBwKaYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmses = {}"
      ],
      "metadata": {
        "id": "YivUEjblMd3b"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)"
      ],
      "metadata": {
        "id": "pOWdfrRqMuJF"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def learn_model(model, epochs=300):\n",
        "  criterion = nn.MSELoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(X_train_tensor)\n",
        "      loss = criterion(outputs, y_train_tensor)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "          val_outputs = model(X_val_tensor)\n",
        "          val_loss = criterion(val_outputs, y_val_tensor)\n",
        "\n",
        "      if (epoch + 1) % 10 == 0:\n",
        "          print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')"
      ],
      "metadata": {
        "id": "uoH9zfGCNRgu"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_test_rmse(model):\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      y_predict_tensor = model(X_test_tensor)\n",
        "      y_predict_np = y_predict_tensor.numpy()\n",
        "      y_test_np = y_test_tensor.numpy()\n",
        "\n",
        "  return np.sqrt(mean_squared_error(y_test_np, y_predict_np))"
      ],
      "metadata": {
        "id": "5YU2JlqNN7Ax"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Линейная регрессия"
      ],
      "metadata": {
        "id": "iIBSsTrUKdd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "model_lin_reg = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 1)\n",
        ")\n",
        "\n",
        "learn_model(model_lin_reg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKM2wnerKbyE",
        "outputId": "9b80ede6-edfb-4ee9-bf1c-86faff2711c1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 319608520704.0000, Val Loss: 311084974080.0000\n",
            "Epoch [20/300], Train Loss: 319484690432.0000, Val Loss: 310963208192.0000\n",
            "Epoch [30/300], Train Loss: 319360892928.0000, Val Loss: 310841409536.0000\n",
            "Epoch [40/300], Train Loss: 319237193728.0000, Val Loss: 310719709184.0000\n",
            "Epoch [50/300], Train Loss: 319113560064.0000, Val Loss: 310598074368.0000\n",
            "Epoch [60/300], Train Loss: 318989991936.0000, Val Loss: 310476505088.0000\n",
            "Epoch [70/300], Train Loss: 318866489344.0000, Val Loss: 310355034112.0000\n",
            "Epoch [80/300], Train Loss: 318743117824.0000, Val Loss: 310233595904.0000\n",
            "Epoch [90/300], Train Loss: 318619746304.0000, Val Loss: 310112288768.0000\n",
            "Epoch [100/300], Train Loss: 318496473088.0000, Val Loss: 309991014400.0000\n",
            "Epoch [110/300], Train Loss: 318373298176.0000, Val Loss: 309869772800.0000\n",
            "Epoch [120/300], Train Loss: 318250156032.0000, Val Loss: 309748662272.0000\n",
            "Epoch [130/300], Train Loss: 318127112192.0000, Val Loss: 309627584512.0000\n",
            "Epoch [140/300], Train Loss: 318004133888.0000, Val Loss: 309506539520.0000\n",
            "Epoch [150/300], Train Loss: 317881221120.0000, Val Loss: 309385658368.0000\n",
            "Epoch [160/300], Train Loss: 317758406656.0000, Val Loss: 309264809984.0000\n",
            "Epoch [170/300], Train Loss: 317635657728.0000, Val Loss: 309143994368.0000\n",
            "Epoch [180/300], Train Loss: 317512974336.0000, Val Loss: 309023277056.0000\n",
            "Epoch [190/300], Train Loss: 317390323712.0000, Val Loss: 308902625280.0000\n",
            "Epoch [200/300], Train Loss: 317267804160.0000, Val Loss: 308782039040.0000\n",
            "Epoch [210/300], Train Loss: 317145284608.0000, Val Loss: 308661518336.0000\n",
            "Epoch [220/300], Train Loss: 317022928896.0000, Val Loss: 308541063168.0000\n",
            "Epoch [230/300], Train Loss: 316900638720.0000, Val Loss: 308420706304.0000\n",
            "Epoch [240/300], Train Loss: 316778315776.0000, Val Loss: 308300414976.0000\n",
            "Epoch [250/300], Train Loss: 316656156672.0000, Val Loss: 308180156416.0000\n",
            "Epoch [260/300], Train Loss: 316534063104.0000, Val Loss: 308059963392.0000\n",
            "Epoch [270/300], Train Loss: 316412002304.0000, Val Loss: 307939868672.0000\n",
            "Epoch [280/300], Train Loss: 316290039808.0000, Val Loss: 307819872256.0000\n",
            "Epoch [290/300], Train Loss: 316168142848.0000, Val Loss: 307699875840.0000\n",
            "Epoch [300/300], Train Loss: 316046344192.0000, Val Loss: 307579977728.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_lin = get_test_rmse(model_lin_reg)\n",
        "rmses['Линейная регрессия'] = rmse_lin\n",
        "print(f\"\\nRMSE on the test set: {rmse_lin:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99LLb1yuLhDZ",
        "outputId": "14946bcd-c9df-47e7-84cd-160f8afd8477"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RMSE on the test set: 552142.6552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейронка 1"
      ],
      "metadata": {
        "id": "vujYDL0eM7C2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn1 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBMlBCOkM8fa",
        "outputId": "4628f3d6-40eb-4758-b69f-4e8e36f60a24"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 321572798464.0000, Val Loss: 312976736256.0000\n",
            "Epoch [20/300], Train Loss: 321032585216.0000, Val Loss: 312443437056.0000\n",
            "Epoch [30/300], Train Loss: 320463175680.0000, Val Loss: 311879598080.0000\n",
            "Epoch [40/300], Train Loss: 319843172352.0000, Val Loss: 311263657984.0000\n",
            "Epoch [50/300], Train Loss: 319149146112.0000, Val Loss: 310572384256.0000\n",
            "Epoch [60/300], Train Loss: 318355013632.0000, Val Loss: 309780054016.0000\n",
            "Epoch [70/300], Train Loss: 317426794496.0000, Val Loss: 308852228096.0000\n",
            "Epoch [80/300], Train Loss: 316321759232.0000, Val Loss: 307746504704.0000\n",
            "Epoch [90/300], Train Loss: 315007369216.0000, Val Loss: 306431426560.0000\n",
            "Epoch [100/300], Train Loss: 313464520704.0000, Val Loss: 304888643584.0000\n",
            "Epoch [110/300], Train Loss: 311692951552.0000, Val Loss: 303121268736.0000\n",
            "Epoch [120/300], Train Loss: 309706784768.0000, Val Loss: 301144014848.0000\n",
            "Epoch [130/300], Train Loss: 307521781760.0000, Val Loss: 298971267072.0000\n",
            "Epoch [140/300], Train Loss: 305143644160.0000, Val Loss: 296608956416.0000\n",
            "Epoch [150/300], Train Loss: 302582530048.0000, Val Loss: 294066094080.0000\n",
            "Epoch [160/300], Train Loss: 299837259776.0000, Val Loss: 291339337728.0000\n",
            "Epoch [170/300], Train Loss: 296907669504.0000, Val Loss: 288429146112.0000\n",
            "Epoch [180/300], Train Loss: 293800181760.0000, Val Loss: 285343711232.0000\n",
            "Epoch [190/300], Train Loss: 290534424576.0000, Val Loss: 282101645312.0000\n",
            "Epoch [200/300], Train Loss: 287121506304.0000, Val Loss: 278712745984.0000\n",
            "Epoch [210/300], Train Loss: 283570470912.0000, Val Loss: 275185729536.0000\n",
            "Epoch [220/300], Train Loss: 279891312640.0000, Val Loss: 271530196992.0000\n",
            "Epoch [230/300], Train Loss: 276095631360.0000, Val Loss: 267757338624.0000\n",
            "Epoch [240/300], Train Loss: 272196501504.0000, Val Loss: 263879884800.0000\n",
            "Epoch [250/300], Train Loss: 268208472064.0000, Val Loss: 259911827456.0000\n",
            "Epoch [260/300], Train Loss: 264146812928.0000, Val Loss: 255868092416.0000\n",
            "Epoch [270/300], Train Loss: 260027547648.0000, Val Loss: 251764047872.0000\n",
            "Epoch [280/300], Train Loss: 255866765312.0000, Val Loss: 247615373312.0000\n",
            "Epoch [290/300], Train Loss: 251680899072.0000, Val Loss: 243437977600.0000\n",
            "Epoch [300/300], Train Loss: 247486119936.0000, Val Loss: 239247491072.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_nn1 = get_test_rmse(model_nn1)\n",
        "rmses['Нейронка 1(64 нейронов + ReLU)'] = rmse_nn1\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo-NApj2OQla",
        "outputId": "36be1e41-7ee5-4984-811c-6864b66baca9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RMSE on the test set: 485809.8146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейронка 2"
      ],
      "metadata": {
        "id": "3JcTYyQHOpo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn2 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn2)\n",
        "\n",
        "rmse_nn2 = get_test_rmse(model_nn2)\n",
        "rmses['Нейронка 2(128 нейронов + ReLU)'] = rmse_nn2\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bBXmNkBOjWL",
        "outputId": "07cb268f-e291-4e4c-89cb-8e2d957f69ba"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 320896466944.0000, Val Loss: 312252203008.0000\n",
            "Epoch [20/300], Train Loss: 319751258112.0000, Val Loss: 311122493440.0000\n",
            "Epoch [30/300], Train Loss: 318552440832.0000, Val Loss: 309935013888.0000\n",
            "Epoch [40/300], Train Loss: 317242310656.0000, Val Loss: 308631011328.0000\n",
            "Epoch [50/300], Train Loss: 315757953024.0000, Val Loss: 307149471744.0000\n",
            "Epoch [60/300], Train Loss: 314053722112.0000, Val Loss: 305448419328.0000\n",
            "Epoch [70/300], Train Loss: 312095997952.0000, Val Loss: 303494234112.0000\n",
            "Epoch [80/300], Train Loss: 309851717632.0000, Val Loss: 301254246400.0000\n",
            "Epoch [90/300], Train Loss: 307297386496.0000, Val Loss: 298706239488.0000\n",
            "Epoch [100/300], Train Loss: 304406331392.0000, Val Loss: 295821737984.0000\n",
            "Epoch [110/300], Train Loss: 301156401152.0000, Val Loss: 292578263040.0000\n",
            "Epoch [120/300], Train Loss: 297529114624.0000, Val Loss: 288958676992.0000\n",
            "Epoch [130/300], Train Loss: 293545967616.0000, Val Loss: 284991586304.0000\n",
            "Epoch [140/300], Train Loss: 289263943680.0000, Val Loss: 280731090944.0000\n",
            "Epoch [150/300], Train Loss: 284716531712.0000, Val Loss: 276206256128.0000\n",
            "Epoch [160/300], Train Loss: 279916707840.0000, Val Loss: 271427141632.0000\n",
            "Epoch [170/300], Train Loss: 274867683328.0000, Val Loss: 266396614656.0000\n",
            "Epoch [180/300], Train Loss: 269598670848.0000, Val Loss: 261145821184.0000\n",
            "Epoch [190/300], Train Loss: 264149401600.0000, Val Loss: 255712247808.0000\n",
            "Epoch [200/300], Train Loss: 258548318208.0000, Val Loss: 250121797632.0000\n",
            "Epoch [210/300], Train Loss: 252811968512.0000, Val Loss: 244388020224.0000\n",
            "Epoch [220/300], Train Loss: 246973775872.0000, Val Loss: 238547468288.0000\n",
            "Epoch [230/300], Train Loss: 241102192640.0000, Val Loss: 232667185152.0000\n",
            "Epoch [240/300], Train Loss: 235251990528.0000, Val Loss: 226799534080.0000\n",
            "Epoch [250/300], Train Loss: 229471617024.0000, Val Loss: 220991488000.0000\n",
            "Epoch [260/300], Train Loss: 223806455808.0000, Val Loss: 215287152640.0000\n",
            "Epoch [270/300], Train Loss: 218297843712.0000, Val Loss: 209727094784.0000\n",
            "Epoch [280/300], Train Loss: 212982366208.0000, Val Loss: 204347146240.0000\n",
            "Epoch [290/300], Train Loss: 207889530880.0000, Val Loss: 199176028160.0000\n",
            "Epoch [300/300], Train Loss: 203038965760.0000, Val Loss: 194233253888.0000\n",
            "\n",
            "RMSE on the test set: 437121.2931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейронка 3"
      ],
      "metadata": {
        "id": "u0MJ0_uzPAMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn3 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn3)\n",
        "\n",
        "rmse_nn3 = get_test_rmse(model_nn3)\n",
        "rmses['Нейронка 3(256 нейронов + ReLU)'] = rmse_nn3\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn3:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMaYm8M7PBjj",
        "outputId": "48cf05c2-585e-4910-9ff1-2919c47653ed"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 320202178560.0000, Val Loss: 311475863552.0000\n",
            "Epoch [20/300], Train Loss: 318066622464.0000, Val Loss: 309365866496.0000\n",
            "Epoch [30/300], Train Loss: 315779645440.0000, Val Loss: 307094814720.0000\n",
            "Epoch [40/300], Train Loss: 313221480448.0000, Val Loss: 304542679040.0000\n",
            "Epoch [50/300], Train Loss: 310262136832.0000, Val Loss: 301581434880.0000\n",
            "Epoch [60/300], Train Loss: 306786828288.0000, Val Loss: 298101112832.0000\n",
            "Epoch [70/300], Train Loss: 302706294784.0000, Val Loss: 294015205376.0000\n",
            "Epoch [80/300], Train Loss: 297947889664.0000, Val Loss: 289252278272.0000\n",
            "Epoch [90/300], Train Loss: 292471472128.0000, Val Loss: 283772321792.0000\n",
            "Epoch [100/300], Train Loss: 286257971200.0000, Val Loss: 277555707904.0000\n",
            "Epoch [110/300], Train Loss: 279332683776.0000, Val Loss: 270631501824.0000\n",
            "Epoch [120/300], Train Loss: 271789981696.0000, Val Loss: 263095320576.0000\n",
            "Epoch [130/300], Train Loss: 263761084416.0000, Val Loss: 255078170624.0000\n",
            "Epoch [140/300], Train Loss: 255390072832.0000, Val Loss: 246715678720.0000\n",
            "Epoch [150/300], Train Loss: 246813851648.0000, Val Loss: 238140342272.0000\n",
            "Epoch [160/300], Train Loss: 238165803008.0000, Val Loss: 229480333312.0000\n",
            "Epoch [170/300], Train Loss: 229564841984.0000, Val Loss: 220848226304.0000\n",
            "Epoch [180/300], Train Loss: 221136519168.0000, Val Loss: 212369113088.0000\n",
            "Epoch [190/300], Train Loss: 213012971520.0000, Val Loss: 204171329536.0000\n",
            "Epoch [200/300], Train Loss: 205314424832.0000, Val Loss: 196372234240.0000\n",
            "Epoch [210/300], Train Loss: 198155730944.0000, Val Loss: 189086679040.0000\n",
            "Epoch [220/300], Train Loss: 191617499136.0000, Val Loss: 182394208256.0000\n",
            "Epoch [230/300], Train Loss: 185766445056.0000, Val Loss: 176363274240.0000\n",
            "Epoch [240/300], Train Loss: 180626325504.0000, Val Loss: 171021451264.0000\n",
            "Epoch [250/300], Train Loss: 176190373888.0000, Val Loss: 166367330304.0000\n",
            "Epoch [260/300], Train Loss: 172422594560.0000, Val Loss: 162371600384.0000\n",
            "Epoch [270/300], Train Loss: 169262792704.0000, Val Loss: 158981668864.0000\n",
            "Epoch [280/300], Train Loss: 166633553920.0000, Val Loss: 156128051200.0000\n",
            "Epoch [290/300], Train Loss: 164448157696.0000, Val Loss: 153731579904.0000\n",
            "Epoch [300/300], Train Loss: 162618064896.0000, Val Loss: 151710433280.0000\n",
            "\n",
            "RMSE on the test set: 386825.7629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейронка 4"
      ],
      "metadata": {
        "id": "fJ_AQG-cPXZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn4 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn4)\n",
        "\n",
        "rmse_nn4 = get_test_rmse(model_nn4)\n",
        "rmses['Нейронка 4(512 нейронов + ReLU)'] = rmse_nn4\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn4:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8D9uNvUPZb2",
        "outputId": "96e6af44-79ce-4713-a67d-65518fcdbf71"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 318666244096.0000, Val Loss: 309799288832.0000\n",
            "Epoch [20/300], Train Loss: 314786709504.0000, Val Loss: 305954226176.0000\n",
            "Epoch [30/300], Train Loss: 310524575744.0000, Val Loss: 301704970240.0000\n",
            "Epoch [40/300], Train Loss: 305641455616.0000, Val Loss: 296818016256.0000\n",
            "Epoch [50/300], Train Loss: 299929600000.0000, Val Loss: 291091218432.0000\n",
            "Epoch [60/300], Train Loss: 293226184704.0000, Val Loss: 284367290368.0000\n",
            "Epoch [70/300], Train Loss: 285415571456.0000, Val Loss: 276528398336.0000\n",
            "Epoch [80/300], Train Loss: 276416757760.0000, Val Loss: 267492261888.0000\n",
            "Epoch [90/300], Train Loss: 266261430272.0000, Val Loss: 257301643264.0000\n",
            "Epoch [100/300], Train Loss: 255162843136.0000, Val Loss: 246171041792.0000\n",
            "Epoch [110/300], Train Loss: 243407781888.0000, Val Loss: 234374774784.0000\n",
            "Epoch [120/300], Train Loss: 231329644544.0000, Val Loss: 222240260096.0000\n",
            "Epoch [130/300], Train Loss: 219346763776.0000, Val Loss: 210181275648.0000\n",
            "Epoch [140/300], Train Loss: 207915057152.0000, Val Loss: 198637944832.0000\n",
            "Epoch [150/300], Train Loss: 197395382272.0000, Val Loss: 187960606720.0000\n",
            "Epoch [160/300], Train Loss: 188105916416.0000, Val Loss: 178465390592.0000\n",
            "Epoch [170/300], Train Loss: 180232159232.0000, Val Loss: 170337927168.0000\n",
            "Epoch [180/300], Train Loss: 173809205248.0000, Val Loss: 163620339712.0000\n",
            "Epoch [190/300], Train Loss: 168745779200.0000, Val Loss: 158247829504.0000\n",
            "Epoch [200/300], Train Loss: 164886151168.0000, Val Loss: 154085539840.0000\n",
            "Epoch [210/300], Train Loss: 161967308800.0000, Val Loss: 150889005056.0000\n",
            "Epoch [220/300], Train Loss: 159682625536.0000, Val Loss: 148379795456.0000\n",
            "Epoch [230/300], Train Loss: 157765206016.0000, Val Loss: 146306809856.0000\n",
            "Epoch [240/300], Train Loss: 156021194752.0000, Val Loss: 144479666176.0000\n",
            "Epoch [250/300], Train Loss: 154325352448.0000, Val Loss: 142766604288.0000\n",
            "Epoch [260/300], Train Loss: 152622776320.0000, Val Loss: 141104971776.0000\n",
            "Epoch [270/300], Train Loss: 150917644288.0000, Val Loss: 139477549056.0000\n",
            "Epoch [280/300], Train Loss: 149174681600.0000, Val Loss: 137840459776.0000\n",
            "Epoch [290/300], Train Loss: 147383975936.0000, Val Loss: 136170643456.0000\n",
            "Epoch [300/300], Train Loss: 145547460608.0000, Val Loss: 134461947904.0000\n",
            "\n",
            "RMSE on the test set: 364463.4181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейронка 5"
      ],
      "metadata": {
        "id": "zQBFC1RCPkqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn5 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(1024, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn5)\n",
        "\n",
        "rmse_nn5 = get_test_rmse(model_nn5)\n",
        "rmses['Нейронка 5(1024 нейронов + ReLU)'] = rmse_nn5\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn5:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmbKVcu2PmhO",
        "outputId": "e5026c7f-69f5-40e2-bdd9-4dadee589f18"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 316415475712.0000, Val Loss: 307293650944.0000\n",
            "Epoch [20/300], Train Loss: 309498970112.0000, Val Loss: 300433997824.0000\n",
            "Epoch [30/300], Train Loss: 301857538048.0000, Val Loss: 292794957824.0000\n",
            "Epoch [40/300], Train Loss: 292993499136.0000, Val Loss: 283894382592.0000\n",
            "Epoch [50/300], Train Loss: 282586185728.0000, Val Loss: 273426169856.0000\n",
            "Epoch [60/300], Train Loss: 270501052416.0000, Val Loss: 261264588800.0000\n",
            "Epoch [70/300], Train Loss: 256802865152.0000, Val Loss: 247475437568.0000\n",
            "Epoch [80/300], Train Loss: 241803001856.0000, Val Loss: 232372174848.0000\n",
            "Epoch [90/300], Train Loss: 226104279040.0000, Val Loss: 216554930176.0000\n",
            "Epoch [100/300], Train Loss: 210501730304.0000, Val Loss: 200800698368.0000\n",
            "Epoch [110/300], Train Loss: 195882778624.0000, Val Loss: 185974112256.0000\n",
            "Epoch [120/300], Train Loss: 183115595776.0000, Val Loss: 172943015936.0000\n",
            "Epoch [130/300], Train Loss: 172967460864.0000, Val Loss: 162493988864.0000\n",
            "Epoch [140/300], Train Loss: 165707350016.0000, Val Loss: 154857537536.0000\n",
            "Epoch [150/300], Train Loss: 160739180544.0000, Val Loss: 149514731520.0000\n",
            "Epoch [160/300], Train Loss: 157170499584.0000, Val Loss: 145658642432.0000\n",
            "Epoch [170/300], Train Loss: 154256965632.0000, Val Loss: 142610366464.0000\n",
            "Epoch [180/300], Train Loss: 151496605696.0000, Val Loss: 139875893248.0000\n",
            "Epoch [190/300], Train Loss: 148695810048.0000, Val Loss: 137240690688.0000\n",
            "Epoch [200/300], Train Loss: 145842749440.0000, Val Loss: 134621601792.0000\n",
            "Epoch [210/300], Train Loss: 142913241088.0000, Val Loss: 131944210432.0000\n",
            "Epoch [220/300], Train Loss: 139931566080.0000, Val Loss: 129204535296.0000\n",
            "Epoch [230/300], Train Loss: 136915517440.0000, Val Loss: 126414880768.0000\n",
            "Epoch [240/300], Train Loss: 133861343232.0000, Val Loss: 123577884672.0000\n",
            "Epoch [250/300], Train Loss: 130772983808.0000, Val Loss: 120700305408.0000\n",
            "Epoch [260/300], Train Loss: 127647645696.0000, Val Loss: 117787844608.0000\n",
            "Epoch [270/300], Train Loss: 124479700992.0000, Val Loss: 114844909568.0000\n",
            "Epoch [280/300], Train Loss: 121287434240.0000, Val Loss: 111888867328.0000\n",
            "Epoch [290/300], Train Loss: 118072467456.0000, Val Loss: 108917923840.0000\n",
            "Epoch [300/300], Train Loss: 114855043072.0000, Val Loss: 105940393984.0000\n",
            "\n",
            "RMSE on the test set: 322834.2326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейронка 6"
      ],
      "metadata": {
        "id": "qMGHVWAWP47v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn6 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 64),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(64, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn6)\n",
        "\n",
        "rmse_nn6 = get_test_rmse(model_nn6)\n",
        "rmses['Нейронка 6(64 нейронов + Sigmoid)'] = rmse_nn6\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn6:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9LUQPQTP604",
        "outputId": "c5b2c63a-8bb2-4ffa-d40a-c16fa4199485"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 321919385600.0000, Val Loss: 313370050560.0000\n",
            "Epoch [20/300], Train Loss: 321918861312.0000, Val Loss: 313369624576.0000\n",
            "Epoch [30/300], Train Loss: 321918468096.0000, Val Loss: 313369198592.0000\n",
            "Epoch [40/300], Train Loss: 321918042112.0000, Val Loss: 313368739840.0000\n",
            "Epoch [50/300], Train Loss: 321917648896.0000, Val Loss: 313368313856.0000\n",
            "Epoch [60/300], Train Loss: 321917190144.0000, Val Loss: 313367920640.0000\n",
            "Epoch [70/300], Train Loss: 321916731392.0000, Val Loss: 313367494656.0000\n",
            "Epoch [80/300], Train Loss: 321916272640.0000, Val Loss: 313367003136.0000\n",
            "Epoch [90/300], Train Loss: 321915781120.0000, Val Loss: 313366511616.0000\n",
            "Epoch [100/300], Train Loss: 321915191296.0000, Val Loss: 313365987328.0000\n",
            "Epoch [110/300], Train Loss: 321914732544.0000, Val Loss: 313365463040.0000\n",
            "Epoch [120/300], Train Loss: 321914273792.0000, Val Loss: 313365004288.0000\n",
            "Epoch [130/300], Train Loss: 321913815040.0000, Val Loss: 313364578304.0000\n",
            "Epoch [140/300], Train Loss: 321913356288.0000, Val Loss: 313364185088.0000\n",
            "Epoch [150/300], Train Loss: 321912897536.0000, Val Loss: 313363693568.0000\n",
            "Epoch [160/300], Train Loss: 321912471552.0000, Val Loss: 313363234816.0000\n",
            "Epoch [170/300], Train Loss: 321912012800.0000, Val Loss: 313362808832.0000\n",
            "Epoch [180/300], Train Loss: 321911586816.0000, Val Loss: 313362382848.0000\n",
            "Epoch [190/300], Train Loss: 321911128064.0000, Val Loss: 313361924096.0000\n",
            "Epoch [200/300], Train Loss: 321910669312.0000, Val Loss: 313361498112.0000\n",
            "Epoch [210/300], Train Loss: 321910243328.0000, Val Loss: 313361039360.0000\n",
            "Epoch [220/300], Train Loss: 321909817344.0000, Val Loss: 313360613376.0000\n",
            "Epoch [230/300], Train Loss: 321909358592.0000, Val Loss: 313360187392.0000\n",
            "Epoch [240/300], Train Loss: 321908899840.0000, Val Loss: 313359728640.0000\n",
            "Epoch [250/300], Train Loss: 321908473856.0000, Val Loss: 313359335424.0000\n",
            "Epoch [260/300], Train Loss: 321908113408.0000, Val Loss: 313358876672.0000\n",
            "Epoch [270/300], Train Loss: 321907687424.0000, Val Loss: 313358483456.0000\n",
            "Epoch [280/300], Train Loss: 321907228672.0000, Val Loss: 313358024704.0000\n",
            "Epoch [290/300], Train Loss: 321906835456.0000, Val Loss: 313357631488.0000\n",
            "Epoch [300/300], Train Loss: 321906376704.0000, Val Loss: 313357238272.0000\n",
            "\n",
            "RMSE on the test set: 557407.7125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейронка 7"
      ],
      "metadata": {
        "id": "Zm-LaYnRQMa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn7 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 128),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(128, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn7)\n",
        "\n",
        "rmse_nn7 = get_test_rmse(model_nn7)\n",
        "rmses['Нейронка 7(128 нейронов + Sigmoid)'] = rmse_nn7\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn7:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNbTjK3AQSxy",
        "outputId": "67cc2c02-39a2-417f-f89f-c78e3f74f746"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 321918795776.0000, Val Loss: 313369460736.0000\n",
            "Epoch [20/300], Train Loss: 321918009344.0000, Val Loss: 313368674304.0000\n",
            "Epoch [30/300], Train Loss: 321917190144.0000, Val Loss: 313367855104.0000\n",
            "Epoch [40/300], Train Loss: 321916370944.0000, Val Loss: 313367035904.0000\n",
            "Epoch [50/300], Train Loss: 321915486208.0000, Val Loss: 313366216704.0000\n",
            "Epoch [60/300], Train Loss: 321914667008.0000, Val Loss: 313365397504.0000\n",
            "Epoch [70/300], Train Loss: 321913749504.0000, Val Loss: 313364447232.0000\n",
            "Epoch [80/300], Train Loss: 321912733696.0000, Val Loss: 313363496960.0000\n",
            "Epoch [90/300], Train Loss: 321911717888.0000, Val Loss: 313362415616.0000\n",
            "Epoch [100/300], Train Loss: 321910669312.0000, Val Loss: 313361465344.0000\n",
            "Epoch [110/300], Train Loss: 321909751808.0000, Val Loss: 313360515072.0000\n",
            "Epoch [120/300], Train Loss: 321908834304.0000, Val Loss: 313359597568.0000\n",
            "Epoch [130/300], Train Loss: 321907949568.0000, Val Loss: 313358712832.0000\n",
            "Epoch [140/300], Train Loss: 321907032064.0000, Val Loss: 313357828096.0000\n",
            "Epoch [150/300], Train Loss: 321906114560.0000, Val Loss: 313356877824.0000\n",
            "Epoch [160/300], Train Loss: 321905065984.0000, Val Loss: 313355862016.0000\n",
            "Epoch [170/300], Train Loss: 321904148480.0000, Val Loss: 313354944512.0000\n",
            "Epoch [180/300], Train Loss: 321903198208.0000, Val Loss: 313354027008.0000\n",
            "Epoch [190/300], Train Loss: 321902313472.0000, Val Loss: 313353109504.0000\n",
            "Epoch [200/300], Train Loss: 321901395968.0000, Val Loss: 313352224768.0000\n",
            "Epoch [210/300], Train Loss: 321900511232.0000, Val Loss: 313351372800.0000\n",
            "Epoch [220/300], Train Loss: 321899659264.0000, Val Loss: 313350520832.0000\n",
            "Epoch [230/300], Train Loss: 321898774528.0000, Val Loss: 313349636096.0000\n",
            "Epoch [240/300], Train Loss: 321897922560.0000, Val Loss: 313348784128.0000\n",
            "Epoch [250/300], Train Loss: 321897005056.0000, Val Loss: 313347964928.0000\n",
            "Epoch [260/300], Train Loss: 321896153088.0000, Val Loss: 313347112960.0000\n",
            "Epoch [270/300], Train Loss: 321895333888.0000, Val Loss: 313346260992.0000\n",
            "Epoch [280/300], Train Loss: 321894514688.0000, Val Loss: 313345441792.0000\n",
            "Epoch [290/300], Train Loss: 321893662720.0000, Val Loss: 313344589824.0000\n",
            "Epoch [300/300], Train Loss: 321892777984.0000, Val Loss: 313343770624.0000\n",
            "\n",
            "RMSE on the test set: 557395.6612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейронка 8"
      ],
      "metadata": {
        "id": "AdqEFyd0Qe94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn8 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 256),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(256, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn8)\n",
        "\n",
        "rmse_nn8 = get_test_rmse(model_nn8)\n",
        "rmses['Нейронка 8(256 нейронов + Sigmoid)'] = rmse_nn8\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn8:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxPpv2RcQhEj",
        "outputId": "194bcdc0-a6aa-4e8b-d394-426b719484a8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 321917485056.0000, Val Loss: 313368117248.0000\n",
            "Epoch [20/300], Train Loss: 321915912192.0000, Val Loss: 313366577152.0000\n",
            "Epoch [30/300], Train Loss: 321914306560.0000, Val Loss: 313364938752.0000\n",
            "Epoch [40/300], Train Loss: 321912700928.0000, Val Loss: 313363333120.0000\n",
            "Epoch [50/300], Train Loss: 321910964224.0000, Val Loss: 313361629184.0000\n",
            "Epoch [60/300], Train Loss: 321908965376.0000, Val Loss: 313359663104.0000\n",
            "Epoch [70/300], Train Loss: 321906999296.0000, Val Loss: 313357664256.0000\n",
            "Epoch [80/300], Train Loss: 321904967680.0000, Val Loss: 313355632640.0000\n",
            "Epoch [90/300], Train Loss: 321902870528.0000, Val Loss: 313353601024.0000\n",
            "Epoch [100/300], Train Loss: 321900871680.0000, Val Loss: 313351634944.0000\n",
            "Epoch [110/300], Train Loss: 321898905600.0000, Val Loss: 313349636096.0000\n",
            "Epoch [120/300], Train Loss: 321897005056.0000, Val Loss: 313347735552.0000\n",
            "Epoch [130/300], Train Loss: 321895104512.0000, Val Loss: 313345900544.0000\n",
            "Epoch [140/300], Train Loss: 321893269504.0000, Val Loss: 313344098304.0000\n",
            "Epoch [150/300], Train Loss: 321891467264.0000, Val Loss: 313342328832.0000\n",
            "Epoch [160/300], Train Loss: 321889599488.0000, Val Loss: 313340493824.0000\n",
            "Epoch [170/300], Train Loss: 321887797248.0000, Val Loss: 313338691584.0000\n",
            "Epoch [180/300], Train Loss: 321885962240.0000, Val Loss: 313336889344.0000\n",
            "Epoch [190/300], Train Loss: 321884127232.0000, Val Loss: 313335054336.0000\n",
            "Epoch [200/300], Train Loss: 321882292224.0000, Val Loss: 313333284864.0000\n",
            "Epoch [210/300], Train Loss: 321880522752.0000, Val Loss: 313331449856.0000\n",
            "Epoch [220/300], Train Loss: 321878753280.0000, Val Loss: 313329713152.0000\n",
            "Epoch [230/300], Train Loss: 321876951040.0000, Val Loss: 313328009216.0000\n",
            "Epoch [240/300], Train Loss: 321875214336.0000, Val Loss: 313326239744.0000\n",
            "Epoch [250/300], Train Loss: 321873510400.0000, Val Loss: 313324568576.0000\n",
            "Epoch [260/300], Train Loss: 321871773696.0000, Val Loss: 313322831872.0000\n",
            "Epoch [270/300], Train Loss: 321870004224.0000, Val Loss: 313321095168.0000\n",
            "Epoch [280/300], Train Loss: 321868333056.0000, Val Loss: 313319424000.0000\n",
            "Epoch [290/300], Train Loss: 321866563584.0000, Val Loss: 313317687296.0000\n",
            "Epoch [300/300], Train Loss: 321864826880.0000, Val Loss: 313315950592.0000\n",
            "\n",
            "RMSE on the test set: 557370.8522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейронка 9"
      ],
      "metadata": {
        "id": "PqDXuXbwQpsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn9 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 512),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(512, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn9)\n",
        "\n",
        "rmse_nn9 = get_test_rmse(model_nn9)\n",
        "rmses['Нейронка 9(512 нейронов + Sigmoid)'] = rmse_nn9\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn9:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5LLb_p0QrDd",
        "outputId": "a75930d7-67df-4fc4-a4d2-0117c023fe88"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 321916960768.0000, Val Loss: 313367461888.0000\n",
            "Epoch [20/300], Train Loss: 321914142720.0000, Val Loss: 313364709376.0000\n",
            "Epoch [30/300], Train Loss: 321911390208.0000, Val Loss: 313361924096.0000\n",
            "Epoch [40/300], Train Loss: 321908441088.0000, Val Loss: 313358974976.0000\n",
            "Epoch [50/300], Train Loss: 321905229824.0000, Val Loss: 313355862016.0000\n",
            "Epoch [60/300], Train Loss: 321901756416.0000, Val Loss: 313352388608.0000\n",
            "Epoch [70/300], Train Loss: 321897922560.0000, Val Loss: 313348554752.0000\n",
            "Epoch [80/300], Train Loss: 321893859328.0000, Val Loss: 313344491520.0000\n",
            "Epoch [90/300], Train Loss: 321889665024.0000, Val Loss: 313340297216.0000\n",
            "Epoch [100/300], Train Loss: 321885241344.0000, Val Loss: 313335971840.0000\n",
            "Epoch [110/300], Train Loss: 321880817664.0000, Val Loss: 313331548160.0000\n",
            "Epoch [120/300], Train Loss: 321876426752.0000, Val Loss: 313327190016.0000\n",
            "Epoch [130/300], Train Loss: 321872035840.0000, Val Loss: 313322864640.0000\n",
            "Epoch [140/300], Train Loss: 321867776000.0000, Val Loss: 313318637568.0000\n",
            "Epoch [150/300], Train Loss: 321863680000.0000, Val Loss: 313314607104.0000\n",
            "Epoch [160/300], Train Loss: 321859780608.0000, Val Loss: 313310707712.0000\n",
            "Epoch [170/300], Train Loss: 321855848448.0000, Val Loss: 313306873856.0000\n",
            "Epoch [180/300], Train Loss: 321851949056.0000, Val Loss: 313303007232.0000\n",
            "Epoch [190/300], Train Loss: 321848115200.0000, Val Loss: 313299173376.0000\n",
            "Epoch [200/300], Train Loss: 321844248576.0000, Val Loss: 313295372288.0000\n",
            "Epoch [210/300], Train Loss: 321840349184.0000, Val Loss: 313291505664.0000\n",
            "Epoch [220/300], Train Loss: 321836548096.0000, Val Loss: 313287802880.0000\n",
            "Epoch [230/300], Train Loss: 321832878080.0000, Val Loss: 313284132864.0000\n",
            "Epoch [240/300], Train Loss: 321829240832.0000, Val Loss: 313280495616.0000\n",
            "Epoch [250/300], Train Loss: 321825570816.0000, Val Loss: 313276891136.0000\n",
            "Epoch [260/300], Train Loss: 321821900800.0000, Val Loss: 313273286656.0000\n",
            "Epoch [270/300], Train Loss: 321818198016.0000, Val Loss: 313269616640.0000\n",
            "Epoch [280/300], Train Loss: 321814462464.0000, Val Loss: 313265881088.0000\n",
            "Epoch [290/300], Train Loss: 321810759680.0000, Val Loss: 313262243840.0000\n",
            "Epoch [300/300], Train Loss: 321807056896.0000, Val Loss: 313258606592.0000\n",
            "\n",
            "RMSE on the test set: 557319.5259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейронка 10"
      ],
      "metadata": {
        "id": "RiQ7hp88Qv_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn10 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 1024),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(1024, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn10)\n",
        "\n",
        "rmse_nn10 = get_test_rmse(model_nn10)\n",
        "rmses['Нейронка 10(1024 нейронов + Sigmoid)'] = rmse_nn10\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn10:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O8KU-hsQxfy",
        "outputId": "7d301310-aad9-48fe-8787-5f8921a4840a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 321915158528.0000, Val Loss: 313365430272.0000\n",
            "Epoch [20/300], Train Loss: 321909620736.0000, Val Loss: 313359925248.0000\n",
            "Epoch [30/300], Train Loss: 321903788032.0000, Val Loss: 313354125312.0000\n",
            "Epoch [40/300], Train Loss: 321897463808.0000, Val Loss: 313347833856.0000\n",
            "Epoch [50/300], Train Loss: 321890615296.0000, Val Loss: 313340985344.0000\n",
            "Epoch [60/300], Train Loss: 321883144192.0000, Val Loss: 313333514240.0000\n",
            "Epoch [70/300], Train Loss: 321875116032.0000, Val Loss: 313325584384.0000\n",
            "Epoch [80/300], Train Loss: 321866629120.0000, Val Loss: 313317130240.0000\n",
            "Epoch [90/300], Train Loss: 321857880064.0000, Val Loss: 313308512256.0000\n",
            "Epoch [100/300], Train Loss: 321848999936.0000, Val Loss: 313299599360.0000\n",
            "Epoch [110/300], Train Loss: 321839890432.0000, Val Loss: 313290555392.0000\n",
            "Epoch [120/300], Train Loss: 321830977536.0000, Val Loss: 313281740800.0000\n",
            "Epoch [130/300], Train Loss: 321822326784.0000, Val Loss: 313273253888.0000\n",
            "Epoch [140/300], Train Loss: 321814134784.0000, Val Loss: 313265127424.0000\n",
            "Epoch [150/300], Train Loss: 321806270464.0000, Val Loss: 313257328640.0000\n",
            "Epoch [160/300], Train Loss: 321798471680.0000, Val Loss: 313249693696.0000\n",
            "Epoch [170/300], Train Loss: 321790803968.0000, Val Loss: 313242124288.0000\n",
            "Epoch [180/300], Train Loss: 321783169024.0000, Val Loss: 313234554880.0000\n",
            "Epoch [190/300], Train Loss: 321775697920.0000, Val Loss: 313227149312.0000\n",
            "Epoch [200/300], Train Loss: 321768161280.0000, Val Loss: 313219678208.0000\n",
            "Epoch [210/300], Train Loss: 321760690176.0000, Val Loss: 313212272640.0000\n",
            "Epoch [220/300], Train Loss: 321753186304.0000, Val Loss: 313204867072.0000\n",
            "Epoch [230/300], Train Loss: 321745813504.0000, Val Loss: 313197592576.0000\n",
            "Epoch [240/300], Train Loss: 321738473472.0000, Val Loss: 313190318080.0000\n",
            "Epoch [250/300], Train Loss: 321731166208.0000, Val Loss: 313183076352.0000\n",
            "Epoch [260/300], Train Loss: 321723858944.0000, Val Loss: 313175867392.0000\n",
            "Epoch [270/300], Train Loss: 321716584448.0000, Val Loss: 313168691200.0000\n",
            "Epoch [280/300], Train Loss: 321709309952.0000, Val Loss: 313161482240.0000\n",
            "Epoch [290/300], Train Loss: 321702133760.0000, Val Loss: 313154338816.0000\n",
            "Epoch [300/300], Train Loss: 321694924800.0000, Val Loss: 313147195392.0000\n",
            "\n",
            "RMSE on the test set: 557219.9465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейронка 11"
      ],
      "metadata": {
        "id": "InnFvaH-SEyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn11 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn11)\n",
        "\n",
        "rmse_nn11 = get_test_rmse(model_nn11)\n",
        "rmses['Нейронка 11((64 нейронов)*2 + ReLU)'] = rmse_nn11\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn11:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeqiZubVSGI2",
        "outputId": "80867560-c0ee-4602-8ff0-3d89d333bf61"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 320590446592.0000, Val Loss: 311906598912.0000\n",
            "Epoch [20/300], Train Loss: 318833459200.0000, Val Loss: 310138208256.0000\n",
            "Epoch [30/300], Train Loss: 316498935808.0000, Val Loss: 307761774592.0000\n",
            "Epoch [40/300], Train Loss: 313189203968.0000, Val Loss: 304385556480.0000\n",
            "Epoch [50/300], Train Loss: 308531134464.0000, Val Loss: 299644026880.0000\n",
            "Epoch [60/300], Train Loss: 302175584256.0000, Val Loss: 293189156864.0000\n",
            "Epoch [70/300], Train Loss: 293788450816.0000, Val Loss: 284685271040.0000\n",
            "Epoch [80/300], Train Loss: 283055915008.0000, Val Loss: 273819238400.0000\n",
            "Epoch [90/300], Train Loss: 269875445760.0000, Val Loss: 260500307968.0000\n",
            "Epoch [100/300], Train Loss: 254428430336.0000, Val Loss: 244901363712.0000\n",
            "Epoch [110/300], Train Loss: 237261029376.0000, Val Loss: 227569811456.0000\n",
            "Epoch [120/300], Train Loss: 219395178496.0000, Val Loss: 209512202240.0000\n",
            "Epoch [130/300], Train Loss: 202265640960.0000, Val Loss: 192142295040.0000\n",
            "Epoch [140/300], Train Loss: 187494154240.0000, Val Loss: 177039769600.0000\n",
            "Epoch [150/300], Train Loss: 176288464896.0000, Val Loss: 165388042240.0000\n",
            "Epoch [160/300], Train Loss: 169038004224.0000, Val Loss: 157611851776.0000\n",
            "Epoch [170/300], Train Loss: 165009801216.0000, Val Loss: 153047138304.0000\n",
            "Epoch [180/300], Train Loss: 162645590016.0000, Val Loss: 150298607616.0000\n",
            "Epoch [190/300], Train Loss: 160730677248.0000, Val Loss: 148244955136.0000\n",
            "Epoch [200/300], Train Loss: 158776639488.0000, Val Loss: 146363236352.0000\n",
            "Epoch [210/300], Train Loss: 156726771712.0000, Val Loss: 144492412928.0000\n",
            "Epoch [220/300], Train Loss: 154623311872.0000, Val Loss: 142579761152.0000\n",
            "Epoch [230/300], Train Loss: 152442765312.0000, Val Loss: 140571443200.0000\n",
            "Epoch [240/300], Train Loss: 150170845184.0000, Val Loss: 138459463680.0000\n",
            "Epoch [250/300], Train Loss: 147791986688.0000, Val Loss: 136237301760.0000\n",
            "Epoch [260/300], Train Loss: 145295671296.0000, Val Loss: 133901254656.0000\n",
            "Epoch [270/300], Train Loss: 142696169472.0000, Val Loss: 131460235264.0000\n",
            "Epoch [280/300], Train Loss: 139955453952.0000, Val Loss: 128891609088.0000\n",
            "Epoch [290/300], Train Loss: 137081520128.0000, Val Loss: 126207197184.0000\n",
            "Epoch [300/300], Train Loss: 134109061120.0000, Val Loss: 123416363008.0000\n",
            "\n",
            "RMSE on the test set: 349146.0625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейронка 12"
      ],
      "metadata": {
        "id": "9SeRB6nbSbbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn12 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn12)\n",
        "\n",
        "rmse_nn12 = get_test_rmse(model_nn12)\n",
        "rmses['Нейронка 12((128 нейронов)*2 + ReLU)'] = rmse_nn12\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn12:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqoN_5YMSctp",
        "outputId": "ff1f7b77-8d69-42a1-8565-842e9cf20233"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 318843453440.0000, Val Loss: 309998813184.0000\n",
            "Epoch [20/300], Train Loss: 314550910976.0000, Val Loss: 305581522944.0000\n",
            "Epoch [30/300], Train Loss: 307719634944.0000, Val Loss: 298535419904.0000\n",
            "Epoch [40/300], Train Loss: 297137045504.0000, Val Loss: 287661555712.0000\n",
            "Epoch [50/300], Train Loss: 281782059008.0000, Val Loss: 271961243648.0000\n",
            "Epoch [60/300], Train Loss: 261183635456.0000, Val Loss: 250981515264.0000\n",
            "Epoch [70/300], Train Loss: 235933089792.0000, Val Loss: 225328611328.0000\n",
            "Epoch [80/300], Train Loss: 208539009024.0000, Val Loss: 197575213056.0000\n",
            "Epoch [90/300], Train Loss: 183978819584.0000, Val Loss: 172676726784.0000\n",
            "Epoch [100/300], Train Loss: 167609024512.0000, Val Loss: 155817492480.0000\n",
            "Epoch [110/300], Train Loss: 160340492288.0000, Val Loss: 147820052480.0000\n",
            "Epoch [120/300], Train Loss: 156549562368.0000, Val Loss: 143598764032.0000\n",
            "Epoch [130/300], Train Loss: 152186224640.0000, Val Loss: 139624464384.0000\n",
            "Epoch [140/300], Train Loss: 147642744832.0000, Val Loss: 135759585280.0000\n",
            "Epoch [150/300], Train Loss: 143105540096.0000, Val Loss: 131709206528.0000\n",
            "Epoch [160/300], Train Loss: 138346790912.0000, Val Loss: 127257419776.0000\n",
            "Epoch [170/300], Train Loss: 133335236608.0000, Val Loss: 122496401408.0000\n",
            "Epoch [180/300], Train Loss: 128086908928.0000, Val Loss: 117524111360.0000\n",
            "Epoch [190/300], Train Loss: 122586144768.0000, Val Loss: 112359030784.0000\n",
            "Epoch [200/300], Train Loss: 116759035904.0000, Val Loss: 106949582848.0000\n",
            "Epoch [210/300], Train Loss: 110618189824.0000, Val Loss: 101283217408.0000\n",
            "Epoch [220/300], Train Loss: 104183562240.0000, Val Loss: 95355486208.0000\n",
            "Epoch [230/300], Train Loss: 97546584064.0000, Val Loss: 89242951680.0000\n",
            "Epoch [240/300], Train Loss: 90855047168.0000, Val Loss: 83080642560.0000\n",
            "Epoch [250/300], Train Loss: 84260151296.0000, Val Loss: 77010567168.0000\n",
            "Epoch [260/300], Train Loss: 77841170432.0000, Val Loss: 71143022592.0000\n",
            "Epoch [270/300], Train Loss: 71710916608.0000, Val Loss: 65580662784.0000\n",
            "Epoch [280/300], Train Loss: 66036215808.0000, Val Loss: 60473462784.0000\n",
            "Epoch [290/300], Train Loss: 60933382144.0000, Val Loss: 55909511168.0000\n",
            "Epoch [300/300], Train Loss: 56496492544.0000, Val Loss: 51970306048.0000\n",
            "\n",
            "RMSE on the test set: 226708.8686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейронка 13"
      ],
      "metadata": {
        "id": "VNN8EtIbSkQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn13 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn13)\n",
        "\n",
        "rmse_nn13 = get_test_rmse(model_nn13)\n",
        "rmses['Нейронка 13((256 нейронов)*2 + ReLU)'] = rmse_nn13\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn13:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "difzrhDMSlnz",
        "outputId": "909ed8e4-b231-4486-82bb-2351ec4a6027"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 317043671040.0000, Val Loss: 307904249856.0000\n",
            "Epoch [20/300], Train Loss: 308161839104.0000, Val Loss: 298667081728.0000\n",
            "Epoch [30/300], Train Loss: 293482725376.0000, Val Loss: 283501002752.0000\n",
            "Epoch [40/300], Train Loss: 271516221440.0000, Val Loss: 260947558400.0000\n",
            "Epoch [50/300], Train Loss: 242373115904.0000, Val Loss: 231190282240.0000\n",
            "Epoch [60/300], Train Loss: 209703124992.0000, Val Loss: 197987729408.0000\n",
            "Epoch [70/300], Train Loss: 181894578176.0000, Val Loss: 169724821504.0000\n",
            "Epoch [80/300], Train Loss: 167249100800.0000, Val Loss: 154333233152.0000\n",
            "Epoch [90/300], Train Loss: 161161265152.0000, Val Loss: 147360219136.0000\n",
            "Epoch [100/300], Train Loss: 153032343552.0000, Val Loss: 139738595328.0000\n",
            "Epoch [110/300], Train Loss: 143963652096.0000, Val Loss: 131854647296.0000\n",
            "Epoch [120/300], Train Loss: 135601889280.0000, Val Loss: 124283355136.0000\n",
            "Epoch [130/300], Train Loss: 127661490176.0000, Val Loss: 116885970944.0000\n",
            "Epoch [140/300], Train Loss: 119409065984.0000, Val Loss: 109189111808.0000\n",
            "Epoch [150/300], Train Loss: 110861893632.0000, Val Loss: 101210693632.0000\n",
            "Epoch [160/300], Train Loss: 102042083328.0000, Val Loss: 93005266944.0000\n",
            "Epoch [170/300], Train Loss: 93146079232.0000, Val Loss: 84793368576.0000\n",
            "Epoch [180/300], Train Loss: 84279861248.0000, Val Loss: 76680192000.0000\n",
            "Epoch [190/300], Train Loss: 75670290432.0000, Val Loss: 68870840320.0000\n",
            "Epoch [200/300], Train Loss: 67600584704.0000, Val Loss: 61627396096.0000\n",
            "Epoch [210/300], Train Loss: 60494151680.0000, Val Loss: 55301689344.0000\n",
            "Epoch [220/300], Train Loss: 54573187072.0000, Val Loss: 50106335232.0000\n",
            "Epoch [230/300], Train Loss: 49974915072.0000, Val Loss: 46146326528.0000\n",
            "Epoch [240/300], Train Loss: 46662316032.0000, Val Loss: 43355025408.0000\n",
            "Epoch [250/300], Train Loss: 44496814080.0000, Val Loss: 41589997568.0000\n",
            "Epoch [260/300], Train Loss: 43221528576.0000, Val Loss: 40607997952.0000\n",
            "Epoch [270/300], Train Loss: 42583052288.0000, Val Loss: 40164966400.0000\n",
            "Epoch [280/300], Train Loss: 42334765056.0000, Val Loss: 40029470720.0000\n",
            "Epoch [290/300], Train Loss: 42268516352.0000, Val Loss: 40012185600.0000\n",
            "Epoch [300/300], Train Loss: 42255196160.0000, Val Loss: 40011759616.0000\n",
            "\n",
            "RMSE on the test set: 202727.7359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейронка 14"
      ],
      "metadata": {
        "id": "2qC-U9EoStYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn14 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn14)\n",
        "\n",
        "rmse_nn14 = get_test_rmse(model_nn14)\n",
        "rmses['Нейронка 14((512 нейронов)*2 + ReLU)'] = rmse_nn14\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn14:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5rGlOxhSvGP",
        "outputId": "a91b3876-bb73-4baf-e6a4-ee6bbfb891b6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 305283923968.0000, Val Loss: 294538706944.0000\n",
            "Epoch [20/300], Train Loss: 272996646912.0000, Val Loss: 260877336576.0000\n",
            "Epoch [30/300], Train Loss: 226870820864.0000, Val Loss: 213599977472.0000\n",
            "Epoch [40/300], Train Loss: 186413301760.0000, Val Loss: 172915589120.0000\n",
            "Epoch [50/300], Train Loss: 176793468928.0000, Val Loss: 161853472768.0000\n",
            "Epoch [60/300], Train Loss: 168273182720.0000, Val Loss: 153494372352.0000\n",
            "Epoch [70/300], Train Loss: 157210984448.0000, Val Loss: 144739418112.0000\n",
            "Epoch [80/300], Train Loss: 144990191616.0000, Val Loss: 132856348672.0000\n",
            "Epoch [90/300], Train Loss: 129261469696.0000, Val Loss: 117406228480.0000\n",
            "Epoch [100/300], Train Loss: 110921203712.0000, Val Loss: 100102692864.0000\n",
            "Epoch [110/300], Train Loss: 91272716288.0000, Val Loss: 82144337920.0000\n",
            "Epoch [120/300], Train Loss: 72962211840.0000, Val Loss: 65725779968.0000\n",
            "Epoch [130/300], Train Loss: 57882869760.0000, Val Loss: 52545429504.0000\n",
            "Epoch [140/300], Train Loss: 47982526464.0000, Val Loss: 44228853760.0000\n",
            "Epoch [150/300], Train Loss: 43368161280.0000, Val Loss: 40670248960.0000\n",
            "Epoch [160/300], Train Loss: 42371928064.0000, Val Loss: 40126308352.0000\n",
            "Epoch [170/300], Train Loss: 42435768320.0000, Val Loss: 40253534208.0000\n",
            "Epoch [180/300], Train Loss: 42383921152.0000, Val Loss: 40178106368.0000\n",
            "Epoch [190/300], Train Loss: 42306502656.0000, Val Loss: 40077058048.0000\n",
            "Epoch [200/300], Train Loss: 42283888640.0000, Val Loss: 40037396480.0000\n",
            "Epoch [210/300], Train Loss: 42265612288.0000, Val Loss: 40018468864.0000\n",
            "Epoch [220/300], Train Loss: 42242699264.0000, Val Loss: 40003567616.0000\n",
            "Epoch [230/300], Train Loss: 42221350912.0000, Val Loss: 39988224000.0000\n",
            "Epoch [240/300], Train Loss: 42200281088.0000, Val Loss: 39970091008.0000\n",
            "Epoch [250/300], Train Loss: 42180599808.0000, Val Loss: 39951867904.0000\n",
            "Epoch [260/300], Train Loss: 42162049024.0000, Val Loss: 39934967808.0000\n",
            "Epoch [270/300], Train Loss: 42144178176.0000, Val Loss: 39919230976.0000\n",
            "Epoch [280/300], Train Loss: 42127138816.0000, Val Loss: 39903875072.0000\n",
            "Epoch [290/300], Train Loss: 42111217664.0000, Val Loss: 39888928768.0000\n",
            "Epoch [300/300], Train Loss: 42096603136.0000, Val Loss: 39874342912.0000\n",
            "\n",
            "RMSE on the test set: 202302.5928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейронка 15"
      ],
      "metadata": {
        "id": "lgYs8MlzS2iW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn15 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(1024, 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(1024, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn15)\n",
        "\n",
        "rmse_nn15 = get_test_rmse(model_nn15)\n",
        "rmses['Нейронка 15((1024 нейронов)*2 + ReLU)'] = rmse_nn15\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn15:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyYf8JJtS3-K",
        "outputId": "0ed1d458-9ce6-4f1c-dc60-4d70a2a71d21"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 270922858496.0000, Val Loss: 255605587968.0000\n",
            "Epoch [20/300], Train Loss: 197525733376.0000, Val Loss: 182004416512.0000\n",
            "Epoch [30/300], Train Loss: 183433052160.0000, Val Loss: 166615564288.0000\n",
            "Epoch [40/300], Train Loss: 165489377280.0000, Val Loss: 151444029440.0000\n",
            "Epoch [50/300], Train Loss: 150648029184.0000, Val Loss: 138329128960.0000\n",
            "Epoch [60/300], Train Loss: 128648716288.0000, Val Loss: 116080762880.0000\n",
            "Epoch [70/300], Train Loss: 99933437952.0000, Val Loss: 89043902464.0000\n",
            "Epoch [80/300], Train Loss: 67561140224.0000, Val Loss: 59812474880.0000\n",
            "Epoch [90/300], Train Loss: 45288361984.0000, Val Loss: 41615704064.0000\n",
            "Epoch [100/300], Train Loss: 42992541696.0000, Val Loss: 41105121280.0000\n",
            "Epoch [110/300], Train Loss: 42914492416.0000, Val Loss: 40649596928.0000\n",
            "Epoch [120/300], Train Loss: 42069594112.0000, Val Loss: 39855390720.0000\n",
            "Epoch [130/300], Train Loss: 42109370368.0000, Val Loss: 39842291712.0000\n",
            "Epoch [140/300], Train Loss: 41989652480.0000, Val Loss: 39753793536.0000\n",
            "Epoch [150/300], Train Loss: 41942147072.0000, Val Loss: 39734063104.0000\n",
            "Epoch [160/300], Train Loss: 41908940800.0000, Val Loss: 39693586432.0000\n",
            "Epoch [170/300], Train Loss: 41873715200.0000, Val Loss: 39647019008.0000\n",
            "Epoch [180/300], Train Loss: 41844334592.0000, Val Loss: 39613358080.0000\n",
            "Epoch [190/300], Train Loss: 41815371776.0000, Val Loss: 39585386496.0000\n",
            "Epoch [200/300], Train Loss: 41788153856.0000, Val Loss: 39557844992.0000\n",
            "Epoch [210/300], Train Loss: 41761947648.0000, Val Loss: 39528845312.0000\n",
            "Epoch [220/300], Train Loss: 41736515584.0000, Val Loss: 39500328960.0000\n",
            "Epoch [230/300], Train Loss: 41712013312.0000, Val Loss: 39474139136.0000\n",
            "Epoch [240/300], Train Loss: 41688342528.0000, Val Loss: 39448657920.0000\n",
            "Epoch [250/300], Train Loss: 41665630208.0000, Val Loss: 39424217088.0000\n",
            "Epoch [260/300], Train Loss: 41643659264.0000, Val Loss: 39400591360.0000\n",
            "Epoch [270/300], Train Loss: 41622450176.0000, Val Loss: 39377932288.0000\n",
            "Epoch [280/300], Train Loss: 41602060288.0000, Val Loss: 39355998208.0000\n",
            "Epoch [290/300], Train Loss: 41582391296.0000, Val Loss: 39334903808.0000\n",
            "Epoch [300/300], Train Loss: 41563557888.0000, Val Loss: 39314563072.0000\n",
            "\n",
            "RMSE on the test set: 200778.1598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейронка 16"
      ],
      "metadata": {
        "id": "sx0uQpRdVNPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn16 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 64),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(64, 64),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(64, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn16)\n",
        "\n",
        "rmse_nn16 = get_test_rmse(model_nn16)\n",
        "rmses['Нейронка 16((64 нейронов)*2 + Sigmoid)'] = rmse_nn16\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn16:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuoPNqn9VOZf",
        "outputId": "13adfc54-7e66-4b15-f2d6-0c9ccd8bdada"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 321919483904.0000, Val Loss: 313370181632.0000\n",
            "Epoch [20/300], Train Loss: 321918828544.0000, Val Loss: 313369526272.0000\n",
            "Epoch [30/300], Train Loss: 321918107648.0000, Val Loss: 313368838144.0000\n",
            "Epoch [40/300], Train Loss: 321917452288.0000, Val Loss: 313368117248.0000\n",
            "Epoch [50/300], Train Loss: 321916731392.0000, Val Loss: 313367429120.0000\n",
            "Epoch [60/300], Train Loss: 321916076032.0000, Val Loss: 313366806528.0000\n",
            "Epoch [70/300], Train Loss: 321915453440.0000, Val Loss: 313366151168.0000\n",
            "Epoch [80/300], Train Loss: 321914863616.0000, Val Loss: 313365495808.0000\n",
            "Epoch [90/300], Train Loss: 321914208256.0000, Val Loss: 313364938752.0000\n",
            "Epoch [100/300], Train Loss: 321913552896.0000, Val Loss: 313364348928.0000\n",
            "Epoch [110/300], Train Loss: 321912930304.0000, Val Loss: 313363693568.0000\n",
            "Epoch [120/300], Train Loss: 321912307712.0000, Val Loss: 313363103744.0000\n",
            "Epoch [130/300], Train Loss: 321911717888.0000, Val Loss: 313362448384.0000\n",
            "Epoch [140/300], Train Loss: 321911062528.0000, Val Loss: 313361825792.0000\n",
            "Epoch [150/300], Train Loss: 321910374400.0000, Val Loss: 313361137664.0000\n",
            "Epoch [160/300], Train Loss: 321909686272.0000, Val Loss: 313360482304.0000\n",
            "Epoch [170/300], Train Loss: 321909063680.0000, Val Loss: 313359859712.0000\n",
            "Epoch [180/300], Train Loss: 321908408320.0000, Val Loss: 313359204352.0000\n",
            "Epoch [190/300], Train Loss: 321907752960.0000, Val Loss: 313358548992.0000\n",
            "Epoch [200/300], Train Loss: 321907064832.0000, Val Loss: 313357959168.0000\n",
            "Epoch [210/300], Train Loss: 321906442240.0000, Val Loss: 313357303808.0000\n",
            "Epoch [220/300], Train Loss: 321905819648.0000, Val Loss: 313356681216.0000\n",
            "Epoch [230/300], Train Loss: 321905229824.0000, Val Loss: 313356058624.0000\n",
            "Epoch [240/300], Train Loss: 321904607232.0000, Val Loss: 313355436032.0000\n",
            "Epoch [250/300], Train Loss: 321904017408.0000, Val Loss: 313354878976.0000\n",
            "Epoch [260/300], Train Loss: 321903427584.0000, Val Loss: 313354256384.0000\n",
            "Epoch [270/300], Train Loss: 321902837760.0000, Val Loss: 313353699328.0000\n",
            "Epoch [280/300], Train Loss: 321902182400.0000, Val Loss: 313353076736.0000\n",
            "Epoch [290/300], Train Loss: 321901592576.0000, Val Loss: 313352486912.0000\n",
            "Epoch [300/300], Train Loss: 321900969984.0000, Val Loss: 313351831552.0000\n",
            "\n",
            "RMSE on the test set: 557402.9214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нерйонка 17"
      ],
      "metadata": {
        "id": "qDKYr8UOVYjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn17 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 128),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(128, 128),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(128, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn17)\n",
        "\n",
        "rmse_nn17 = get_test_rmse(model_nn17)\n",
        "rmses['Нейронка 17((128 нейронов)*2 + Sigmoid)'] = rmse_nn17\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn17:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU9yS83XVZki",
        "outputId": "77e8ec2f-58c5-4c72-e13f-ec2365697c9b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 321918468096.0000, Val Loss: 313369100288.0000\n",
            "Epoch [20/300], Train Loss: 321917026304.0000, Val Loss: 313367691264.0000\n",
            "Epoch [30/300], Train Loss: 321915715584.0000, Val Loss: 313366413312.0000\n",
            "Epoch [40/300], Train Loss: 321914503168.0000, Val Loss: 313365200896.0000\n",
            "Epoch [50/300], Train Loss: 321913389056.0000, Val Loss: 313364086784.0000\n",
            "Epoch [60/300], Train Loss: 321912274944.0000, Val Loss: 313362972672.0000\n",
            "Epoch [70/300], Train Loss: 321911095296.0000, Val Loss: 313361825792.0000\n",
            "Epoch [80/300], Train Loss: 321909915648.0000, Val Loss: 313360678912.0000\n",
            "Epoch [90/300], Train Loss: 321908736000.0000, Val Loss: 313359532032.0000\n",
            "Epoch [100/300], Train Loss: 321907621888.0000, Val Loss: 313358352384.0000\n",
            "Epoch [110/300], Train Loss: 321906409472.0000, Val Loss: 313357205504.0000\n",
            "Epoch [120/300], Train Loss: 321905229824.0000, Val Loss: 313355993088.0000\n",
            "Epoch [130/300], Train Loss: 321904082944.0000, Val Loss: 313354878976.0000\n",
            "Epoch [140/300], Train Loss: 321902870528.0000, Val Loss: 313353699328.0000\n",
            "Epoch [150/300], Train Loss: 321901690880.0000, Val Loss: 313352552448.0000\n",
            "Epoch [160/300], Train Loss: 321900511232.0000, Val Loss: 313351372800.0000\n",
            "Epoch [170/300], Train Loss: 321899397120.0000, Val Loss: 313350193152.0000\n",
            "Epoch [180/300], Train Loss: 321898250240.0000, Val Loss: 313349079040.0000\n",
            "Epoch [190/300], Train Loss: 321897103360.0000, Val Loss: 313347932160.0000\n",
            "Epoch [200/300], Train Loss: 321895923712.0000, Val Loss: 313346818048.0000\n",
            "Epoch [210/300], Train Loss: 321894842368.0000, Val Loss: 313345703936.0000\n",
            "Epoch [220/300], Train Loss: 321893728256.0000, Val Loss: 313344622592.0000\n",
            "Epoch [230/300], Train Loss: 321892646912.0000, Val Loss: 313343475712.0000\n",
            "Epoch [240/300], Train Loss: 321891500032.0000, Val Loss: 313342394368.0000\n",
            "Epoch [250/300], Train Loss: 321890353152.0000, Val Loss: 313341247488.0000\n",
            "Epoch [260/300], Train Loss: 321889239040.0000, Val Loss: 313340133376.0000\n",
            "Epoch [270/300], Train Loss: 321887961088.0000, Val Loss: 313338888192.0000\n",
            "Epoch [280/300], Train Loss: 321886683136.0000, Val Loss: 313337675776.0000\n",
            "Epoch [290/300], Train Loss: 321885437952.0000, Val Loss: 313336430592.0000\n",
            "Epoch [300/300], Train Loss: 321884225536.0000, Val Loss: 313335218176.0000\n",
            "\n",
            "RMSE on the test set: 557388.0481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейронка 18"
      ],
      "metadata": {
        "id": "GQl__EFcVghX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn18 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 256),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(256, 256),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(256, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn18)\n",
        "\n",
        "rmse_nn18 = get_test_rmse(model_nn18)\n",
        "rmses['Нейронка 18((256 нейронов)*2 + Sigmoid)'] = rmse_nn18\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn18:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOf6SdVaVln5",
        "outputId": "6d5cd664-61ba-46a8-f777-409bb8855181"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 321916993536.0000, Val Loss: 313367429120.0000\n",
            "Epoch [20/300], Train Loss: 321914241024.0000, Val Loss: 313364774912.0000\n",
            "Epoch [30/300], Train Loss: 321912078336.0000, Val Loss: 313362743296.0000\n",
            "Epoch [40/300], Train Loss: 321910210560.0000, Val Loss: 313360875520.0000\n",
            "Epoch [50/300], Train Loss: 321908277248.0000, Val Loss: 313358974976.0000\n",
            "Epoch [60/300], Train Loss: 321906409472.0000, Val Loss: 313357107200.0000\n",
            "Epoch [70/300], Train Loss: 321904476160.0000, Val Loss: 313355206656.0000\n",
            "Epoch [80/300], Train Loss: 321902575616.0000, Val Loss: 313353273344.0000\n",
            "Epoch [90/300], Train Loss: 321900576768.0000, Val Loss: 313351307264.0000\n",
            "Epoch [100/300], Train Loss: 321898545152.0000, Val Loss: 313349373952.0000\n",
            "Epoch [110/300], Train Loss: 321896546304.0000, Val Loss: 313347309568.0000\n",
            "Epoch [120/300], Train Loss: 321894514688.0000, Val Loss: 313345310720.0000\n",
            "Epoch [130/300], Train Loss: 321892417536.0000, Val Loss: 313343311872.0000\n",
            "Epoch [140/300], Train Loss: 321890385920.0000, Val Loss: 313341214720.0000\n",
            "Epoch [150/300], Train Loss: 321888354304.0000, Val Loss: 313339215872.0000\n",
            "Epoch [160/300], Train Loss: 321886322688.0000, Val Loss: 313337249792.0000\n",
            "Epoch [170/300], Train Loss: 321884291072.0000, Val Loss: 313335218176.0000\n",
            "Epoch [180/300], Train Loss: 321882193920.0000, Val Loss: 313333121024.0000\n",
            "Epoch [190/300], Train Loss: 321880096768.0000, Val Loss: 313331023872.0000\n",
            "Epoch [200/300], Train Loss: 321878032384.0000, Val Loss: 313328959488.0000\n",
            "Epoch [210/300], Train Loss: 321875902464.0000, Val Loss: 313326862336.0000\n",
            "Epoch [220/300], Train Loss: 321873772544.0000, Val Loss: 313324797952.0000\n",
            "Epoch [230/300], Train Loss: 321871675392.0000, Val Loss: 313322668032.0000\n",
            "Epoch [240/300], Train Loss: 321869545472.0000, Val Loss: 313320570880.0000\n",
            "Epoch [250/300], Train Loss: 321867415552.0000, Val Loss: 313318506496.0000\n",
            "Epoch [260/300], Train Loss: 321865318400.0000, Val Loss: 313316376576.0000\n",
            "Epoch [270/300], Train Loss: 321863221248.0000, Val Loss: 313314344960.0000\n",
            "Epoch [280/300], Train Loss: 321861124096.0000, Val Loss: 313312247808.0000\n",
            "Epoch [290/300], Train Loss: 321859026944.0000, Val Loss: 313310183424.0000\n",
            "Epoch [300/300], Train Loss: 321856929792.0000, Val Loss: 313308151808.0000\n",
            "\n",
            "RMSE on the test set: 557363.8267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейронка 19"
      ],
      "metadata": {
        "id": "93RyJWSCVhv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn19 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 512),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(512, 512),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(512, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn19)\n",
        "\n",
        "rmse_nn19 = get_test_rmse(model_nn19)\n",
        "rmses['Нейронка 19((512 нейронов)*2 + Sigmoid)'] = rmse_nn19\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn19:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEIjda6xVq3v",
        "outputId": "bd0985ae-3751-4c3e-c9df-d737e1cffdef"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 321913192448.0000, Val Loss: 313363529728.0000\n",
            "Epoch [20/300], Train Loss: 321909424128.0000, Val Loss: 313359990784.0000\n",
            "Epoch [30/300], Train Loss: 321906212864.0000, Val Loss: 313356779520.0000\n",
            "Epoch [40/300], Train Loss: 321902837760.0000, Val Loss: 313353437184.0000\n",
            "Epoch [50/300], Train Loss: 321899397120.0000, Val Loss: 313349996544.0000\n",
            "Epoch [60/300], Train Loss: 321895792640.0000, Val Loss: 313346457600.0000\n",
            "Epoch [70/300], Train Loss: 321892188160.0000, Val Loss: 313342820352.0000\n",
            "Epoch [80/300], Train Loss: 321888452608.0000, Val Loss: 313339150336.0000\n",
            "Epoch [90/300], Train Loss: 321884717056.0000, Val Loss: 313335447552.0000\n",
            "Epoch [100/300], Train Loss: 321880817664.0000, Val Loss: 313331613696.0000\n",
            "Epoch [110/300], Train Loss: 321876951040.0000, Val Loss: 313327779840.0000\n",
            "Epoch [120/300], Train Loss: 321872953344.0000, Val Loss: 313323782144.0000\n",
            "Epoch [130/300], Train Loss: 321868922880.0000, Val Loss: 313319817216.0000\n",
            "Epoch [140/300], Train Loss: 321864990720.0000, Val Loss: 313315885056.0000\n",
            "Epoch [150/300], Train Loss: 321860993024.0000, Val Loss: 313311920128.0000\n",
            "Epoch [160/300], Train Loss: 321857060864.0000, Val Loss: 313308053504.0000\n",
            "Epoch [170/300], Train Loss: 321853063168.0000, Val Loss: 313304088576.0000\n",
            "Epoch [180/300], Train Loss: 321849098240.0000, Val Loss: 313300156416.0000\n",
            "Epoch [190/300], Train Loss: 321845133312.0000, Val Loss: 313296224256.0000\n",
            "Epoch [200/300], Train Loss: 321841168384.0000, Val Loss: 313292292096.0000\n",
            "Epoch [210/300], Train Loss: 321837170688.0000, Val Loss: 313288392704.0000\n",
            "Epoch [220/300], Train Loss: 321833238528.0000, Val Loss: 313284427776.0000\n",
            "Epoch [230/300], Train Loss: 321829273600.0000, Val Loss: 313280561152.0000\n",
            "Epoch [240/300], Train Loss: 321825374208.0000, Val Loss: 313276661760.0000\n",
            "Epoch [250/300], Train Loss: 321821442048.0000, Val Loss: 313272827904.0000\n",
            "Epoch [260/300], Train Loss: 321817608192.0000, Val Loss: 313268994048.0000\n",
            "Epoch [270/300], Train Loss: 321813708800.0000, Val Loss: 313265160192.0000\n",
            "Epoch [280/300], Train Loss: 321809842176.0000, Val Loss: 313261326336.0000\n",
            "Epoch [290/300], Train Loss: 321806008320.0000, Val Loss: 313257525248.0000\n",
            "Epoch [300/300], Train Loss: 321802108928.0000, Val Loss: 313253658624.0000\n",
            "\n",
            "RMSE on the test set: 557315.1456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейронка 20"
      ],
      "metadata": {
        "id": "sMxKX94VVj9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model_nn20 = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 1024),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(1024, 1024),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(1024, 1)\n",
        ")\n",
        "\n",
        "learn_model(model=model_nn20)\n",
        "\n",
        "rmse_nn20 = get_test_rmse(model_nn20)\n",
        "rmses['Нейронка 20((1024 нейронов)*2 + Sigmoid)'] = rmse_nn20\n",
        "print(f\"\\nRMSE on the test set: {rmse_nn20:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSYBu6GaV0bX",
        "outputId": "8aaafc0d-edd2-441e-d4d9-4f865805b654"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Train Loss: 321906900992.0000, Val Loss: 313357107200.0000\n",
            "Epoch [20/300], Train Loss: 321900347392.0000, Val Loss: 313350684672.0000\n",
            "Epoch [30/300], Train Loss: 321893793792.0000, Val Loss: 313344196608.0000\n",
            "Epoch [40/300], Train Loss: 321887109120.0000, Val Loss: 313337544704.0000\n",
            "Epoch [50/300], Train Loss: 321880358912.0000, Val Loss: 313330827264.0000\n",
            "Epoch [60/300], Train Loss: 321873543168.0000, Val Loss: 313324077056.0000\n",
            "Epoch [70/300], Train Loss: 321866661888.0000, Val Loss: 313317294080.0000\n",
            "Epoch [80/300], Train Loss: 321859616768.0000, Val Loss: 313310281728.0000\n",
            "Epoch [90/300], Train Loss: 321852375040.0000, Val Loss: 313303040000.0000\n",
            "Epoch [100/300], Train Loss: 321844838400.0000, Val Loss: 313295634432.0000\n",
            "Epoch [110/300], Train Loss: 321837170688.0000, Val Loss: 313287966720.0000\n",
            "Epoch [120/300], Train Loss: 321829240832.0000, Val Loss: 313280069632.0000\n",
            "Epoch [130/300], Train Loss: 321821016064.0000, Val Loss: 313271975936.0000\n",
            "Epoch [140/300], Train Loss: 321812692992.0000, Val Loss: 313263718400.0000\n",
            "Epoch [150/300], Train Loss: 321804271616.0000, Val Loss: 313255395328.0000\n",
            "Epoch [160/300], Train Loss: 321795915776.0000, Val Loss: 313247105024.0000\n",
            "Epoch [170/300], Train Loss: 321787592704.0000, Val Loss: 313238847488.0000\n",
            "Epoch [180/300], Train Loss: 321779269632.0000, Val Loss: 313230655488.0000\n",
            "Epoch [190/300], Train Loss: 321771044864.0000, Val Loss: 313222496256.0000\n",
            "Epoch [200/300], Train Loss: 321762852864.0000, Val Loss: 313214337024.0000\n",
            "Epoch [210/300], Train Loss: 321754628096.0000, Val Loss: 313206210560.0000\n",
            "Epoch [220/300], Train Loss: 321746436096.0000, Val Loss: 313198149632.0000\n",
            "Epoch [230/300], Train Loss: 321738276864.0000, Val Loss: 313190121472.0000\n",
            "Epoch [240/300], Train Loss: 321730215936.0000, Val Loss: 313182060544.0000\n",
            "Epoch [250/300], Train Loss: 321722122240.0000, Val Loss: 313174065152.0000\n",
            "Epoch [260/300], Train Loss: 321714061312.0000, Val Loss: 313166102528.0000\n",
            "Epoch [270/300], Train Loss: 321706065920.0000, Val Loss: 313158172672.0000\n",
            "Epoch [280/300], Train Loss: 321698037760.0000, Val Loss: 313150242816.0000\n",
            "Epoch [290/300], Train Loss: 321690075136.0000, Val Loss: 313142345728.0000\n",
            "Epoch [300/300], Train Loss: 321682046976.0000, Val Loss: 313134448640.0000\n",
            "\n",
            "RMSE on the test set: 557208.4791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Результаты разных настроек"
      ],
      "metadata": {
        "id": "sItqm2qIXwOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "table = PrettyTable()\n",
        "table.title = \"Обучение нейронных сетей на 300 эпох без scale датасета\"\n",
        "table.field_names = [\"Конфигурация модели\", \"RMSE\"]\n",
        "\n",
        "for k,v in rmses.items():\n",
        "  name, rmse = k,v\n",
        "  if name == \"Нейронка 1(128 нейронов + ReLU)\":\n",
        "    name = \"Нейронка 2(128 нейронов + ReLU)\"\n",
        "  if name == \"Нейронка 1(256 нейронов + ReLU)\":\n",
        "    name = \"Нейронка 3(256 нейронов + ReLU)\"\n",
        "  if name == \"Нейронка 1(512 нейронов + ReLU)\":\n",
        "    name = \"Нейронка 4(512 нейронов + ReLU)\"\n",
        "  if name == \"Нейронка 1(1024 нейронов + ReLU)\":\n",
        "    name = \"Нейронка 5(1024 нейронов + ReLU)\"\n",
        "\n",
        "  table.add_row([name, f\"{v:.4f}\"])\n",
        "\n",
        "print(table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7rK_yD5XvEL",
        "outputId": "6fc9f985-2e85-4a4a-deff-abd3f6a42634"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------+\n",
            "| Обучение нейронных сетей на 300 эпох без scale датасета |\n",
            "+------------------------------------------+--------------+\n",
            "|           Конфигурация модели            |     RMSE     |\n",
            "+------------------------------------------+--------------+\n",
            "|            Линейная регрессия            | 552142.6552  |\n",
            "|      Нейронка 1(64 нейронов + ReLU)      | 485809.8146  |\n",
            "|     Нейронка 2(128 нейронов + ReLU)      | 437121.2931  |\n",
            "|     Нейронка 3(256 нейронов + ReLU)      | 386825.7629  |\n",
            "|     Нейронка 4(512 нейронов + ReLU)      | 364463.4181  |\n",
            "|     Нейронка 5(1024 нейронов + ReLU)     | 322834.2326  |\n",
            "|    Нейронка 6(64 нейронов + Sigmoid)     | 557407.7125  |\n",
            "|    Нейронка 7(128 нейронов + Sigmoid)    | 557395.6612  |\n",
            "|    Нейронка 8(256 нейронов + Sigmoid)    | 557370.8522  |\n",
            "|    Нейронка 9(512 нейронов + Sigmoid)    | 557319.5259  |\n",
            "|   Нейронка 10(1024 нейронов + Sigmoid)   | 557219.9465  |\n",
            "|   Нейронка 11((64 нейронов)*2 + ReLU)    | 349146.0625  |\n",
            "|   Нейронка 12((128 нейронов)*2 + ReLU)   | 226708.8686  |\n",
            "|   Нейронка 13((256 нейронов)*2 + ReLU)   | 202727.7359  |\n",
            "|   Нейронка 14((512 нейронов)*2 + ReLU)   | 202302.5928  |\n",
            "|  Нейронка 15((1024 нейронов)*2 + ReLU)   | 200778.1598  |\n",
            "|  Нейронка 16((64 нейронов)*2 + Sigmoid)  | 557402.9214  |\n",
            "| Нейронка 17((128 нейронов)*2 + Sigmoid)  | 557388.0481  |\n",
            "| Нейронка 18((256 нейронов)*2 + Sigmoid)  | 557363.8267  |\n",
            "| Нейронка 19((512 нейронов)*2 + Sigmoid)  | 557315.1456  |\n",
            "| Нейронка 20((1024 нейронов)*2 + Sigmoid) | 557208.4791  |\n",
            "+------------------------------------------+--------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nn_rmses = {k: v for k, v in rmses.items() if 'Нейронка' in k}\n",
        "\n",
        "neurons = [64, 128, 256, 512, 1024]\n",
        "\n",
        "rmse_groups = {\n",
        "    'Single Layer + ReLU': [],\n",
        "    'Single Layer + Sigmoid': [],\n",
        "    'Two Layers + ReLU': [],\n",
        "    'Two Layers + Sigmoid': []\n",
        "}\n",
        "\n",
        "for name, rmse in nn_rmses.items():\n",
        "    if 'ReLU' in name:\n",
        "        if '*2' in name:\n",
        "            rmse_groups['Two Layers + ReLU'].append(rmse)\n",
        "        else:\n",
        "            rmse_groups['Single Layer + ReLU'].append(rmse)\n",
        "    elif 'Sigmoid' in name:\n",
        "        if '*2' in name:\n",
        "            rmse_groups['Two Layers + Sigmoid'].append(rmse)\n",
        "        else:\n",
        "            rmse_groups['Single Layer + Sigmoid'].append(rmse)\n",
        "\n",
        "for key in rmse_groups:\n",
        "    sorted_pairs = sorted(zip(neurons, rmse_groups[key]))\n",
        "    rmse_groups[key] = [rmse for neuron, rmse in sorted_pairs]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for label, data in rmse_groups.items():\n",
        "    if data: # Only plot if there is data for the group\n",
        "        plt.plot(neurons, data, marker='o', label=label)\n",
        "\n",
        "plt.xlabel('Количество нейронов в скрытых слоях')\n",
        "plt.ylabel('RMSE')\n",
        "plt.title('RMSE нейронных сетей в зависимости от количества нейронов и архитектуры')\n",
        "plt.xticks(neurons)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "wh4OsSVDb2_1",
        "outputId": "83b1e78e-7873-4a92-9e72-94be257636bd"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}